version: "3"
services:
  prometheus:
    image: prom/prometheus:v2.4.3
    container_name: 'prometheus'
    volumes:
    - ./config/:/etc/prometheus/
    - ./config/localtime:/etc/localtime:ro
    ports:
     - '9090:9090'
  grafana:
    image: grafana/grafana:5.2.4
    container_name: 'grafana'
    ports:
      - '3000:3000'
    volumes:
      - ./grafana/config/grafana.ini:/etc/grafana/grafana.ini  #grafana报警邮件配置
      - ./grafana/provisioning/:/etc/grafana/provisioning/  #配置grafana的prometheus数据源
      - ./config/localtime:/etc/localtime:ro
    env_file:
      - ./grafana/config.monitoring  #grafana登录配置
    depends_on:
      - prometheus  #grafana需要在prometheus之后启动
  elasticsearch:
    image: elasticsearch:6.4.0
    container_name: elasticsearch
    environment:
      - "cluster.name=elasticsearch" #设置集群名称为elasticsearch
      - "discovery.type=single-node" #以单一节点模式启动
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m" #设置使用jvm内存大小，稍微配置大点，不然有可能启动不成功
    volumes:
      - /usr/local/var/log/elasticsearch/plugins:/usr/share/elasticsearch/plugins #插件文件挂载
      - /usr/local/var/log/elasticsearch/data:/usr/share/elasticsearch/data #数据文件挂载
    ports:
      - 9200:9200
      - 9300:9300
  kibana:
    image: kibana:6.4.0
    container_name: kibana
    links:  #同一个compose文件管理的服务可以直接用服务名访问，如果要给服务取别名则可以用links实现，如下面的es就是elasticsearch服务的别名
      - elasticsearch:es #可以用es这个域名访问elasticsearch服务
    depends_on:
      - elasticsearch #kibana在elasticsearch启动之后再启动
    environment:
      - "elasticsearch.hosts=http://es:9200" #设置访问elasticsearch的地址
    ports:
      - 5601:5601
  redis:
    image: redis
    container_name: redis
    command: redis-server /etc/redis/redis.conf --appendonly yes
    volumes:
      - /usr/local/var/redis/data/:/data/
      - ./redis/redis.conf:/etc/redis/redis.conf
      - ./config/localtime:/etc/localtime:ro
    ports:
      - 6379:6379
  redis_exporter:
    image: oliver006/redis_exporter:v1.6.1-arm
    container_name: redis_exporter
    volumes:
      - ./config/localtime:/etc/localtime:ro
    environment:
      - "REDIS_ADDR=redis://192.168.3.9:6379"
      - "REDIS_PASSWORD=886887"
    ports:
      - 9121:9121
    depends_on:
      - redis
  mysql:
    image: mysql/mysql-server:5.7
    container_name: mysql
    command: mysqld --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci --default-authentication-plugin=mysql_native_password
    restart: always
    environment:
      - "TZ=Asia/Shanghai" # 设置容器时区与宿主机保持一致
      - "MYSQL_ROOT_PASSWORD=886887"
    volumes:
      - ./config/localtime:/etc/localtime:ro # 设置容器时区与宿主机保持一致
      - /usr/local/var/mysql:/var/lib/mysql # 映射数据库保存目录到宿主机，防止数据丢失
      - ./mysql:/etc/mysql # 映射数据库配置文件
    ports:
      - 3306:3306
  mysql_exporter:
    image: prom/mysqld-exporter
    container_name: mysql_exporer
    volumes:
      - ./config/localtime:/etc/localtime:ro
    ports:
      - 9104:9104
    environment:
      - "DATA_SOURCE_NAME=root:886887@(192.168.3.9:3306)/final"
    depends_on:
      - mysql
  jenkins:
    container_name: webjenkins
    image: 'jenkins/jenkins:lts'
    restart: always
    environment:
      - TZ=Asia/Shanghai
    ports:
      - '3083:8080'
      - '50001:50000'
    volumes:
      - ./jenkins-data:/var/jenkins_home:z
      - ./jenkins-data/docker.sock:/var/run/docker.sock
    network_mode: "bridge"
  zk:
    image: zookeeper
    restart: always
    container_name: zk
    hostname: zk
    ports:
      - "2181:2181"
    volumes:
      - ./config/localtime:/etc/localtime
      - /usr/local/var/zookeeper/zoo1/data:/data
      - /usr/local/var/zookeeper/zoo1/datalog:/datalog
    environment:
      ZOO_MY_ID: 1
      ZOO_SERVERS: server.1=zk:2888:3888;2181
  kafka:
    image: wurstmeister/kafka       # 镜像
    volumes:
      - ./config/localtime:/etc/localtime # 挂载位置（kafka镜像和宿主机器之间时间保持一直）
    ports:
      - "9092:9092"
    depends_on:
      - zk
    links:
      - zk
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 10.180.7.140   # 修改:宿主机IP
      KAFKA_ZOOKEEPER_CONNECT: zk:2181       # 卡夫卡运行是基于zookeeper的
      KAFKA_ADVERTISED_PORT: 9092
      KAFKA_LOG_RETENTION_HOURS: 120
      KAFKA_MESSAGE_MAX_BYTES: 10000000
      KAFKA_REPLICA_FETCH_MAX_BYTES: 10000000
      KAFKA_GROUP_MAX_SESSION_TIMEOUT_MS: 60000
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_DELETE_RETENTION_MS: 1000
  kafka-manager:
    container_name: kafka-manager
    image: sheepkiller/kafka-manager                # 镜像：开源的web管理kafka集群的界面
    links:
      - zk
      - kafka
    environment:
      ZK_HOSTS: zk:2181
      KAFKA_BROKERS: kafka:9092
    volumes:
    - ./config/localtime:/etc/localtime
    ports:
      - "9001:9000"